---
title: "Locating Long Polling Lines with Twitter Data 🍕🗳🇺🇸️"
author: "Asako Mikami"
date: '`r format(Sys.time(), "%B %e, %Y")`'
output: 
    prettydoc::html_pretty:
        default: true
        theme: leonids
    bookdown::html_document2:
        df_print: paged
        toc: true
        toc_float: true
        fig_caption: true
        theme: spacelab
---

```{r setup, warning = FALSE, message = FALSE, results='hide', echo = FALSE}
rm(list = ls())
x <- c("tidyverse", "magrittr", "RColorBrewer", "rio", "rjson",
       "lubridate", "knitr", "kableExtra", "listviewer",
       "purrrlyr", "GGally", "gridExtra")
lapply(x, library, character.only = TRUE, quietly = TRUE, verbose = FALSE)
rm(x)
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE,
                      fig.align = "center")
options(knitr.table.format = "html")
load("data/clean_pizza.Rdata")
load("data/counts.Rdata")
load("data/2018-election-results.Rdata")
load("data/map_data.Rdata")
load("data/acs_cd.Rdata")
load("data/mod_df.Rdata")
load("data/missed_opp.Rdata")
```




# Introduction 🗳️

The inspiration for this project came during the 2018 midterm election when I came across a Twitter account called [`@PizzaToThePolls`](https://twitter.com/PizzaToThePolls). On Election Day, Pizza to the Polls was tweeting about delivering pizzas to polling locations across the United States. 

<blockquote class="twitter-tweet"><p lang="ja" dir="ltr">Pizza 1300 S Grand Ave, Santa Ana, CA 92705, USA?<br>. ∧＿∧ <br> (´･ω･)<br>　 |　⌒Ｙ⌒　/ /<br>　 \ヽ　 ｜　 ﾉ／<br>　　＼ ﾄー🍕ーｲ /<br>　　 ｜ ミ土彡 ｜<br> <br>5 pizzas ABSOLUTELY <br> <br>via <a href="https://t.co/34xXjQiPJc">https://t.co/34xXjQiPJc</a></p>&mdash; Pizza to the Polls (@PizzaToThePolls) <a href="https://twitter.com/PizzaToThePolls/status/1060035393968660480?ref_src=twsrc%5Etfw">November 7, 2018</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

The goal of this project is to collect the polling locations where Pizza to the Polls delivered pizzas on the 2018 Midterm Election and learn about the profile of voters who reached out to Pizza to the Polls. The rest of the analysis proceeds as follows:

1. explain data collection method;
2. create an interactive map of the polling addresses;
3. conduct exploratory analysis (bag-of-words and regression);
4. present recommenations for how Pizza to the Polls can improve its outreach for the upcoming election;
5. share what I learned from this project. 


## About Pizza To the Polls 

<img src="fig/PizzaToThePolls_logo.png" alt="logo" width="200"/>

[Pizza to the Polls](https://polls.pizza/about/) (abbreviated PTTP) is a 501(c)(4) nonprofit organization that receives reports about long polling lines on various social media platforms and requests pizza deliveries to polling locations.[^more] Although PTTP is not officially affiliated with any political party in the United States, there is an obvious partisan flavor to their Twitter activity (more detais below). To be clear, unlike 501(c)(3) organizations, 501(c)(4) organizations are allowed to engage in lobbying activity so long as the purpose of lobbying is to promote their social welfare objectives. They also do not lose their tax-exemption status from engaging in electoral campaign activities (i.e. activities influencing electoral results or advocating for a candidate) so long as those activities remain secondary to their primary missions.[^secondary] 

[^more]:[This article](https://zapier.com/blog/pizza-to-the-polls-automation/?utm_medium=social&utm_source=twitter) from *zapier* explains how the organization delivers pizzas. 

[^secondary]: From the IRS website, https://www.irs.gov/charities-non-profits/other-non-profits/social-welfare-organizations. 


## Collecting tweets 

I used Twitter API to [search for tweets](https://developer.twitter.com/en/docs/tweets/search/overview) posted by PTTP on 2018 Midterm Election Day (November 6th, 2018) and [look up accounts](https://developer.twitter.com/en/docs/accounts-and-users/follow-search-get-users/overview) followed by PTTP. Because there is a technical limit to collecting direct data on individual Twitter users who were reporting long lines to PTTP, the alternative solution is to infer their profile based on the profiles of verified Twitter accounts followed by PTTP. The assumption is that the population of users who identify with the political vision projected by PTTP's following is the population that is most likely to know about and reach out to PTTP on the Election day. 


### Searching for tweets 

First I made a query asking how many tweets were posted per hour by PTTP from 00:00 of November 6th, 2018 to 02:00 of November 7th, 2018.[^timezone] Inspecting this count query response, I decided to restrict the timeframe from 11:00 and 23:59 of November 6th, 2018. In total, I retrieved `r sum(raw_counts$count) %>% format(big.mark = ",", scientific = FALSE)` raw tweets. The figure below shows the hourly distribution. 


[^timezone]: It seems that PTTP does not have geolocation enabled on its Twitter account, so it is not possible to tell the time zone. Even if I assume that the account activity is generated in Pacific Standard Time, the timeframe that I selected would adequately cover the last polling location that was open in the mainland United States.

```{r ggplot_raw_counts}
knitr::include_graphics("./fig/tweets_per_hour.png")
```



Next, I processed the texts to remove any special characters, url's, and @'s, and parsed the cleaned text to detect whether it contained any street address. This reduced the number of relevant tweets to `r sum(parsed_counts$count_parsed) %>% format(big.mark = ',', scientific = FALSE)`, which is about 5% of the original sample of tweets. The figure below shows the hourly distribution of tweets containing street addresses. 


```{r ggplot_parsed_counts}
knitr::include_graphics("fig/parsed_tweets_per_hour.png")
```


### Looking up friends 

As of January 22nd, 2020, PTTP is [following](https://twitter.com/PizzaToThePolls/following) 399 accounts on Twitter. For each account, I collected their account name, location (if available), URL (if available), profile description, whether the account is verified, the number of followers, and the date the account was created. I display the 203 verified accounts below. The order that the accounts are listed reflect the order in which PTTP followed the accounts.[^order] 

[^order]: I didn't think of looking up PTTP's following until January 2020. There is no query method that returns a history of a user's follow-unfollow activity, so I can't verify whether PTTP was following these same accounts during the 2018 Midterm Election. 


```{r}
friends_ver <- import("./data/csv/friends_of_PTTP.csv", header = TRUE) %>%   
        dplyr::select(-V1) %>% 
        filter(verified == TRUE) %>%
        mutate(id = as.character(id)) %>%
        dplyr::select(-id, -verified, name, everything())
lst <- setNames(by_row(friends_ver, ~ unlist(.x), .collate = "list")$.out, 
                friends_ver$name)
reactjson(lst, collapsed = 1)
```



## Geocoding addresses

I used Google's [Geocoding API](https://developers.google.com/maps/documentation/geocoding/start) to parse the addresses and locate the geocoordinates of the addresses. From the API response, I scraped the street number, route, state, county, zipcode, longitude, and latitutde. The following list shows the first 6 entries of the dataset.

```{r, echo = FALSE}
load("data/clean_pizza.Rdata")
```


```{r all_locs, echo = FALSE, warning = FALSE}
head <- all_locs %>% 
    dplyr::select(id, clean_text, lat, lng, 
                  st_num, route, city, county, zipcode, state_abbv) %>% head() 
lst <- setNames(by_row(head, ~ unlist(.x), .collate = "list")$.out, 
                head$id)
reactjson(lst, collapsed = 1)
```


```{r}
unique_states <- all_locs %>% group_by(state_abbv) %>% summarize(count = n())
unique_cities <- all_locs %>% group_by(city, state_abbv) %>% summarize(count = n())
```


According to my sample, on 2018 Election day PTTP delivered pizzas to `r nrow(unique_locs)` unique addresses across `r nrow(unique_states)` different states and `r nrow(unique_cities)` different cities.[^numbers] 

[^numbers]: On their website, PTTP [says](https://polls.pizza/about/) that in 2018 they delivered pizzas to "611 polling places across 41 states." The discrepancy between my numbers and theirs may be due to their counting pizzas delivered throughout the year, including those made during special elections that happened earlier in the year. 


## 2018 Midterm Election data

```{r}
load("data/2018-election-results.Rdata")
```

I scraped 2018 Midterm congressional and gubernatorial election results from their Wikipedia pages. For all House, Senate, and gubernatorial races, I scraped the winning candidate's and the second runner's names (`candidate1` and `candidate2`), parties (`party1` and `party2`), and final voteshares in percentages (`share1` and `share2`). There are four congressional districts that had special elections prior to November, namely `r us_cd$label[is.na(us_cd$key)]`. Twenty-three states did not have a senate election, and twenty states did not have a gubernatorial election. Districts that fall into any of these cases are given "No election" label for that election. 

I also consulted the Cook Political Report's most recent ratings prior to November 6th, 2018 to label whether the race was considered a key for the Democratic Party's takeover of the legislative branch (`key`).[^CPR] If a race was ranked as leaning to either party or a toss-up, I labeled the race as a key race.[^outlets] Lists of key House, Senate, and governors seats are presented below. 

```{r}
cat("Key House races: \n", house_key %>% reduce(paste, sep = ", ") %>% str_wrap(width = 80), "\n")
cat("Key Senate races: \n", senate_key, "\n")
cat("Key governor races: \n", governor_key, "\n")
```

Because 2018 was noted for the number of female candidates on the ballot, I also record the number of women candidates who proceeded to the general election for each race. In total, `r house_races$women %>% as.numeric() %>% sum()` women were on the ballot for House races, `r senate_races$women %>% as.numeric() %>% sum()` women for Senate races, and `r governor_races$women %>% as.numeric() %>% sum()` women for gubernatorial races. 

```{r summary_table}
cat("Key x women contingency table, House races, unit = district\n")
xtabs(~ women + key, data = house_races)
cat("Key x women contingency table, Senate races, unit = state\n")
xtabs(~ women + key, data = senate_races)
cat("Key x women contigency table, governor races, unit = state\n")
xtabs(~ women + key, data = governor_races)
```





[^CPR]: "2018 House Race Ratings," *The Cook Political Report*, October 30, 2018, [link](https://cookpolitical.com/ratings/house-race-ratings/187550); "2018 Governor Race Ratings, *The Cook Political Report*, October 26, 2018, [link](https://cookpolitical.com/ratings/governor-race-ratings/187543); "2018 Senate Race Ratings," *The Cook Political Report*, October 26, 2018, [link](https://cookpolitical.com/ratings/senate-race-ratings/187540).


[^outlets]: I compiled a list of key House, Senate, and gubernatorial races mentioned by various media outlets and were rated as either toss-up, leaning Republican, or leaning Democratic by the Cook Political Report. "The Washington Post's Senate Race Ratings," *Washington Post*, November 2nd, 2018, [link](https://www.washingtonpost.com/graphics/2018/politics/senate-ratings/); "The Top 10 House Races of 2018," *Washington Post*, March 18, 2018, [link](https://www.washingtonpost.com/news/the-fix/wp/2018/03/18/the-top-10-house-races-of-2018/); "The top races for control of governors' mansions," *Vox*, November 19, 2018, [link](https://www.vox.com/a/midterms-2018/top-governor-races); "The battlefield to control the House of Representatives is huge," *Vox*, Novebmer 19, 2018, [link](https://www.vox.com/a/midterms-2018/top-house-races); "The most contested Senate races," *Vox*, November 19, 2018, [link](https://www.vox.com/a/midterms-2018/top-senate-races).

[^women]: "2018 Summary of Women Candidates," Center for American Women and Politics, November 14, 2018, [link](https://cawp.rutgers.edu/potential-candidate-summary-2018).


# Interactive map exported as Shiny app

I created [an interactive map](https://asakomikami.shinyapps.io/pizza_to_the_polls/) with `tmap` package (v2.3.1) in R and published it as a RShiny app. There are markers placed on polling locations where pizzas were delivered; the number on the markers counts the number of deliveries made to that location. The map has three layers. The layers color the districts or states that held key races for House, Senate, and governor seats. 

<a href="https://asakomikami.shinyapps.io/pizza_to_the_polls/"><img src="fig/screenshot_map.png" alt="2018 midterm pizza deliveries" height="400px"></a>

# Analysis

One goal of this project is to learn how PTTP---as a nonprofit organization working towards increasing voter turnout by motivating voters to stay in line with pizzas---can improve its level of outreach, which I measure by counting the number of congressional districts that had pizza deliveries. I want to learn the profile of voters who were most likely to know and reach out to PTTP on Election day. I also want to know which districts had close races but did not have voters contacting PTTP; these are places where higher turnout could have shifted the result and therefore constitute missed opportunities for PTTP. 


## Bag of Words

Since PTTP relies on social media platforms such as Twitter to collect reports of long polling lines, young people are generally more likely to know about PTTP out of all groups of voters. Even if they do not follow PTTP, they might learn about the nonprofit's existence indirectly through their social network, celebrity accounts, or campaign accounts that they follow. 

I looked up PTTP's following, scraped their profile descriptions, and counted the most common words. The top twenty-five most frequent terms along with its frequencies are shown below.[^top50] By the frequency of media terminology, PTTP's following is mostly comprised of journalists, editors, and political pundits.  

[^top50]: I am excluding English stop words (e.g. "and") and custom stop words that appear very frequently in Twitter profiles ('twitter', 'email', 'https', 'com', 'politics', 'gmail', 'account', 'tweets', 'views', 'american', 'state', 'opinions'). 

```{r}
file <- file("data/friends/top_50terms.txt", open = "r")
top50 <- readLines(file)
for (i in 1:25){
        print(top50[i])
}
close(file)

```




```{r}
keywords <- c("representative", "senator", "governor", "candidate", 
        "campaign", "movement", "our")
create_regex <- function(string){
        reg <- string %>% map(~ str_c("(?:^|\\W*)", .x, "(?:$|\\W*)")) 
        return(reduce(reg, ~paste(.x, .y, sep = "|")))
}
keywords_reg <- create_regex(keywords)
friends_key <- import("data/csv/friends_of_PTTP.csv", header = TRUE) %>%
        mutate(id = as.character(id)) %>%
        filter(str_detect(tolower(description), keywords_reg))  
```

Below I have filtered accounts of former or current federal office holders, campaign managers, and advocacy groups by flagging profile descriptions that mention one of the following words: "representative", "senator", "governor", "candidate", "campaign", "movement", "our."[^our] Note that these words are politically neutral: they neither explicitly nor implicitly imply any allegiance to a specific policy position. Therefore, the Twitter accounts that pass through this filter should only reflect PTTP's political bias. The result is `r dim(friends_key)[1]` accounts shown below. 

[^our]: The 1st person plural possessive, "our," is a commonly used word in profile description of advocacy groups regardless of their political issue and ideology.

```{r}
library(listviewer)
lst <- setNames(by_row(friends_key, ~ unlist(.x), .collate = "list")$.out, 
                friends_key$name)
reactjson(lst, collapsed = 1)
```

What stands out in the list are March For Our Lives and their founders (Jacyln Corin, Cam Kasky, and David Hogg). Gun control and women's reproductive rights are the two most divisive issues in U.S. politics. The fact that anti-gun control and anti-abortion advocacy groups do not appear in the result provides strong evidence that PTTP identifies more strongly towards progressively liberal agenda. And though I cannot verify this with the data, by social network theory, I claim that the same can be said for voters who were most likely to have contacted PTTP on the Election day. 


## Regression models

The selection mechanism behind the kind of voters who would contact PTTP  should manifest in the characteristic of districts that had long lines and had pizzas delivered on Election day. These characteristics are 

- whether the district was holding one of the key House, Senate, or gubernatorial races: `key_rep`, `key_sen`, `key_gov`; 
- whether the first and second candidates for House, Senate, or gubernatorial races were women: `women_rep`, `women_sen`, `women_gov`; 
- and district-level socioeconomic variables, log-transformed: `medianHouseInc_log` (logged median household income), `blackPop_log` (logged Black population), `totalPop_log` (logged total population), `age18to24_log` (logged population of ages 18 to 24).[^socioeconomic]

[^socioeconomic]: The socioeconomic data comes from U.S. Census 2017 American Community Survey retrieved by `tidycensus` `r packageVersion("tidycensus")` R package.


### Pairwise plots

The first panel shows pairwise plots for numerical variables, namely the outcome variable *count*, logged total population (*log total pop*), logged median household income (*log median house inc.*), logged Black population share (*log Black pop.*), logged population share of age group 18 to 24 (*log age 18-24*). None of the pairs have strong correlation to worry about multicollinearity. *log Black pop.* and *log ages 18-24* are positively and negatively correlated with *count* respectively, but the smoothed conditional mean lines are pulled by extreme *count* values. 


```{r}
load("data/mod_df.Rdata")
```

```{r ggpair_num}
knitr::include_graphics("./fig/ggpairs_num.png")
```


The second panel shows pariwise plots of categorical variable. Because the overwhelming number of zeros make the plots difficult to read, I filtered out the zeros. The first row shows the size of logged count depending on whether the district was holding a key House, Senate, or gubernatorial election. It is interesting that the trend for Senate and governor races is opposite of that of House races: key Senate and governor races have higher counts with smaller variance whereas the key House races have lower count values. Likewise, when there are more women on the ballot, Senate and governor races tend to have higher count values, but the trend is reversed for House raes. 


```{r ggpairs_cat}
knitr::include_graphics("./fig/ggpairs_cat_nozeros.png")
```



The histogram below shows that a vast majority of congressional districts (approximately 80 percent) did not have pizza deliveries from PTTP at any of their polling locations. This suggests that reporting a long line to PTTP on the Election day was a rare event. Since our count data has excess zeros, the best fitting model would incorporate the assumption that the data generating process behind the count values is separate from the process behind the zeros. 


```{r hist_cd, results="asis"}
knitr::include_graphics("fig/hist_cd.png")
```



### Count data regression model

I want to run a regression model to show how the predictor variables are associated with the count values. While negative binomial and poisson regressions are often used to model count data, negative binomial is better suited when there's over-dispersion, i.e. the variance of the outcome variable is greater than the mean. I will run both and then choose the better fitting model based on their diagnostics. Additionally, I am specifying the dispersion parameter by supplying its estimate, $\hat{\sigma}^2 = \dfrac{D(y, \mu)}{n-p}$ where the nominator, $D( y, \mu)$, is the model deviance and the denominator, $n-p$, is the degrees of freedom.



```{r mod_base}
library(MASS)
mod_base <- glm.nb(count ~ key_rep + key_sen + key_gov + 
               women_rep + women_sen + women_gov +  
               medianHouseInc_log +  
               blackPopShare_log + age18to24Share_log + totalPop_log,
           data = mod_df) 
sigma2 <- deviance(mod_base)/df.residual(mod_base)
mod_pois <- glm(count ~ key_rep + key_sen + key_gov + 
               women_rep + women_sen + women_gov +  
               medianHouseInc_log +  
               blackPopShare_log + age18to24Share_log +
               totalPop_log,
           data = mod_df, family = poisson)
```


Below I plot the residuals against the predicted mean value. The smaller range of the y-axis scale on the negative binomial plot tells me that the negative binomial has a better fit than the Poisson model. 

```{r}
color <- brewer.pal(3, "Set1")
df <- cbind("base_fitted" = fitted.values(mod_base), 
            "base_resid" = residuals(mod_base),
            "pois_fitted" = fitted.values(mod_pois), 
            "pois_resid" = residuals(mod_pois)) %>%
    as.data.frame()
base <- ggplot(data = df, aes(x = base_fitted, y = base_resid)) +
    geom_point(color = color[2]) + theme_minimal(base_size = 12) + 
    ggtitle("Negative binomial") + xlab("") + ylab("")
pois <- ggplot(data = df, aes(x = pois_fitted, y = pois_resid)) +
    geom_point(color = color[1]) + theme_minimal(base_size = 12) +
    ggtitle("Poisson")+ xlab("") + ylab("")
grid.arrange(base, pois, nrow = 1, left = "residuals", bottom = "predicted mean values")
```


The result of the negative binomial model fit confirms a lot of what I already gauged from the preliminary analysis. 

- Districts with women candidates in the race were more likely to have had pizza deliveries. 
- Districts holding key Senate and governor races were more likely to have reached out to Pizza to the Polls than key House races.
- Districts with higher share of Blacks and ages 18 to 24 are associated with more pizza delivery counts. 

```{r}
summary(mod_base, dispersion = sigma2)
```


## Propensity score outliers 

So far, I have been modeling the count values. However, I am also interested in whether these predictors made any difference in whether *any* pizza deliveries were made to a district. I imagine that once someone reports a long line to PTTP, then there is a high chance that another pizza delivery will be requested shortly by a word of the mouth. In light of this, it seems that the more interesting outcome to study is the zeros vs. non-zeros. I create another outcome variable, `zero` for each district $i$ where 
    $$ \texttt{zero}_i = \begin{cases} \texttt{TRUE} & \; \text{if }\texttt{count}_i = 0 \\
                                        \texttt{FALSE} & \; \text{if }\texttt{count}_i > 0 \end{cases}.$$ 
I will use a logistic regression to model this new outcome variable against election-related predictors, namely `key_rep`, `key_sen`, `key_gov`, `women_rep`, `women_sen`, and `women_gov`.


```{r}
load(file = "data/missed_opp.Rdata")
```

I am also interested in identifying districts where no pizza deliveries were requested even though their demographics and elections were similar to districts that did have pizza deliveries. These are the districts where more voter turnout could have influenced the result and where Pizza to the Polls should reach out. Therefore, I am going to plot the distribution of propensity scores of observations with `zero == TRUE` against the propensity scores of observations with `zero == FALSE`.

```{r}
knitr::include_graphics(path = "fig/pscore_hist.png")
```

Here, the propensity score is the probability of having `zero == TRUE`. Naturally the mass of bottom histogram is shifted towards the left and the mass of top histogram towards the right. However, there are also a few observations with relatively low propensity scores in the top histogram. I define *missed opportunities* as districts with zero counts that have propensity score below 0.65. The table below lists these missed opportunities. To make the values of numeric variables more comprehensible, I have binned these variables into deciles (`medianHouseInc_q`, `totalPop_q`, `blackPopShare_q`, `age18to24_q`). 

```{r}
missed_opp %>% rmarkdown::paged_table()
```

None of the districts in the table had key House races, continuing the trend we've seen in the main result, but they still had woman candidate running from the Democratic party including LA-03, LA-06, NC-07, and NC-12, where the (male) GOP incumbents won at comfortable margin. This suggests to me that these are districts would have welcomed the help of nonprofits like Pizza to the Polls. 

# Lessons for the 2020 election

If I were working at Pizza to the Polls and was tasked with improving the organization's outreach for the upcoming 2020 election, I would make two recommendations to their operation. First is to **pay attention to key Senate and gubernatorial elections**. Although the probability that the Democrats would take the Senate was low, voters waiting to vote for the key Senate elections were more likely to know and contact Pizza to the Polls than those voting in key House districts. On the other hand, Democrats were vying to win key governorships such as Floria. Georgia where Stacey Abrams was running for governor was also the state that had much controversy over deliberate voter suppression before the election. It is unsurprising that the largest number of pizza deliveries to a single polling location was observed in Georgia. Since senators and governors are elected by the whole state, reaching out to candidates running for these offices is a more efficient way of spreading information about Pizza to the Polls.

My second recommendation is to **reach out to women candidates**. All the districts named as missed opportunities were districts where a woman was running for the House, Senate, or governor. [Past studies](https://fivethirtyeight.com/features/democrats-primaries-candidates-demographics/) have shown that women are less likely than men to run for office. Even though 2018 saw a remarkable number of women challengers on the ballot across the country, they were still more likely than their male counterpart to have had experience as elected officials. Women tend to set higher bars on themselves when making a career choice in politics, and they still face [explicit and implicit sexism](https://fivethirtyeight.com/audio-features/when-women-run/) while on the campaign trail and in office. Thus, although many of the missed opportunities were not one of the key races of 2018 Midterm, supporting women breaking into higher offices would naturally align with PTTP's democratic agenda as evidenced by my bag-of-words analysis. I would recommend Pizza to the Polls to actively engage with campaigns of women candidates and spread awarenss of the organization. 


# Personal commentary

This is a full-stacked project where I collected the data myself (with my own money) and conducted much analysis as I can to get the most out of the data. 

Majority of my time was spent on **cleaning and augmenting the data** by scraping election results from Wikipedia and external sources and merging them together. Even while doing the final analysis, I have had to go back to my code to fix incorrect entries, which attests to how [important](https://hackernoon.com/the-ai-hierarchy-of-needs-18f111fcc007) this [underrated](https://twitter.com/vboykis/status/1054408259149299712?s=20) process is. 

This project made a heavy use of API's: Twitter API, Google's Geocoding API, and US Census API. I tried three ways of **storing credentials**: saving keys in credential files, saving keys in the system environment, and [saving keys in a .env file](http://jonathansoma.com/lede/foundations-2019/classes/apis/keeping-api-keys-secret/). I ended up sticking to the third method for two reasons. First, `dotenv` package is available both for Python and R. Second, since I had to regenerate the API keys more than once during this project, I liked having a file that I could easily edit instead of opening the system environment through the terminal. Additionally, I finally learned the utility of .gitignore. 

Third, this project has motivated me to learn more about **data visualization**. There are many `ggplot2`-related packages out there like `ggfacet` that I haven't used yet. Even for the simple plots, there are simple modifications that I wanted to do such as using colored text in titles [instead of legends](https://twitter.com/djnavarro/status/1222952500237520897?s=20).

Lastly, I was surprised and delighted by how much I was able to learn from the data. At first I was disappointed to have only identified 160 or so polling locations as it was too small a sample size for an academic publication. But I didn't want all the data I collected and processed to go to waste, so I changed my goal by **taking the perspective of Pizza to the Polls and asking what the data tells me about the organization's level of outreach**. As a result, I was able to construct more narrow questions that my data could answer. This experience has taught me how fulfilling doing data science outside of academic research can be. 

